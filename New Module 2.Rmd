---
title: 'Module 2: Review of frequentist hypothesis testing for two independent samples'
output: word_document
---

## Disclaimer
Module 2 is a review of frequentist statistical methods. If the material covered in Module 2 is new for you, we recommend consulting a statistics textbook, such as Peck & Devore (2011), Witte & Witte (2017), or McClave & Sincih (2017), before continuing on to Modules 3 and 4. 

## The Example
Imagine a nursing home has hired you to conduct some statistical analyses. In Module 1, you measured the cognitive state of a sample of the nursing home's patients using the Mini-Mental State Examination (MMSE; Folstein, Folstein, & McHugh, 1975) and estimated the mean and standard deviation. Now you will conduct another statistical analysis for the nursing home. 

Imagine that in your literature review you came across a few articles on the increased risk of cognitive impairment for individuals with low education (see e.g., Stern, Gurland, Tatemichi, Tang, Wilder, & Mayeux, 1994; Letenneur, Gilleron, Commenges, Helmer, Orgogozo, & Dartigues, 1999; Le Carret, Lafont, Letenneur, Dartigues, Mayo, & Fabrigoule, 2003). __The nursing home would now like to know whether the mean cognitive ability of their patients with low levels of education is significantly lower than the mean cognitive ability of their patients with high levels of education.__

## The Data
Imagine you administer the MMSE to a new sample of 60 nursing home patients to obtain a measure of their cognitive state. __The MMSE scores will serve as the outcome variable in the analysis.__ The nursing home will give you access to demographic information on their patients, including which of them completed no more than a high school education and which of them obtained some form of education beyond high school. __This binary education level variable will serve as the predictor in the analysis.__

Because this is a hypothetical example, we will simulate the 60 MMSE-like scores along with a binary variable representing education level. The data will be simulated such that the mean of the simulated MMSE scores is lower for the low education group than for the high education group. "Low education" is defined as completing no more than a high school education, and "high education" is defined as completing some form of education beyond high school. In the simulation below, the low education group is given the label "0" and the high education group is given the label "1". To run the simulation, open a new R script in RStudio, copy and paste the following code, and run it. 
```{r, results = "hide", warning = FALSE, message = FALSE}
set.seed(1)
nrep <- 30 # Tell the simulation that there will be 30 observations per group
ngroup <- 2 # Tell the simulation that there will be two groups (low and high education)
b0 <- 22 # Tell the simulation that the low education group's MMSE scores will be simulated from a distribution with a mean of 22
b1 <- 0.75 # Tell the simulation that the high education group's MMSE scores will be simulated from a distribution with a mean of 22.5 (b0 + b1)
educ <- rep(c("0", "1"), each = nrep) # Simulate the predictor variable
err <- rnorm(n = ngroup*nrep, mean = 0, sd = 1.25) # Simulate 60 residuals from a distribution with a mean of 0 and standard deviation of 1.25
MMSE <- b0 + b1*(educ == "1") + err # Simulate the outcome variable
simdata <- data.frame(MMSE, educ) # Create a dataframe containing the simulated variables MMSE and educ
```

Let's view the first few lines of the simulated dataset, which should consist of MMSE scores for 60 nursing home patients and a binary variable indicating whether each individual falls into group "0" or group "1". Copy and paste the following code into your R script and run it.
```{r, results = "hide", warning = FALSE, message = FALSE}
head(simdata)
```

Let's also output the mean of the MMSE scores for each group. Copy and paste the following code into your R script and run it.
```{r, results = "hide", warning = FALSE, message = FALSE}
mean(simdata$MMSE[educ=="0"]) # Calculate the mean of the simulated MMSE scores for the low education group (group "0")
mean(simdata$MMSE[educ=="1"]) # Calculate the mean of the simulated MMSE scores for the high education group (group "1")
```

Note that the MMSE scores were simulated such that the mean of MMSE scores for group "0" is less than the mean of MMSE scores for group "1". 

## Visualizing the Simulated Scores
Copy and paste the following code into your R script and run it to produce a histogram of the simulated MMSE scores for each group.
```{r, results = "hide", warning = FALSE, message = FALSE}
par(mfrow = c(1, 2)) # Create a plotting window that will display the histograms side-by-side
hist(simdata$MMSE[educ=="0"], main = 'Histogram for Group "0"', breaks = 5, prob = T, xlab = "Simulated MMSE Scores") 
abline(v = mean(simdata$MMSE[educ=="0"]), col = "red", lwd=2) # Overlay a red line at the sample mean for group "0"
hist(simdata$MMSE[educ=="1"], main = 'Histogram for Group "1"', breaks = 5, prob = T, xlab = "Simulated MMSE Scores") 
abline(v = mean(simdata$MMSE[educ=="1"]), col = "red", lwd=2) # Overlay a red line at the sample mean for group "1"
```

## Testing the Assumption of Normality
In the following analysis, we will fit a statistical model that assumes the outcome variable is normally distributed in the population. Although the histograms above suggest that the data could have been sampled from a normal population distribution, let's use the Shapiro-Wilk test of normality to evaluate this. Copy and paste the following code into your R script and run it.
```{r, results = "hide", warning = FALSE, message = FALSE}
shapiro.test(simdata$MMSE[educ=="0"]) # Shapiro-Wilk test of normality for group "0"
shapiro.test(simdata$MMSE[educ=="1"]) # Shapiro-Wilk test of normality for group "1"
```
The results of the Shapiro-Wilk tests are insignificant (p > .05), so we fail to reject the null hypothesis. In other words, there is not enough evidence to suggest that the simulated MMSE scores are non-normally distributed.

## The Analysis
In the simulation above, we verified that the data were simulated such that the mean of the simulated MMSE scores for the low education group (group "0") is less than the mean of the simulated MMSE scores for the high education group (group "1"). Now we need to conduct an analysis to determine whether this observed difference in means is statistically significant. That is, the statistical analysis determines whether the observed difference in means is more likely to be due to chance or to some real difference in the population.

You probably remember from your undergraduate psychology statistics course that __two independent samples t-tests are used to compare the means of two independent groups__. We are going to conduct a one-tailed t-test, so the null and alternative hypotheses are:

$H_0: \mu_2-\mu_1=0$ and

$H_1: \mu_2-\mu_1\neq0$,
where $\mu_1$ is the population mean for the low education group, $\mu_2$ is the population mean for the high education group,  and $\mu_2-\mu_1$ is the estimated difference between $\mu_1$ and $\mu_2$.

In Module 1, we fit a linear model to the MMSE scores, producing estimates of the population mean $\mu$, the standard error of the estimate of $\mu$, and the residual standard error $\sigma$. In this module, we will also fit a linear model to the MMSE scores but we will include education level as a binary predictor. Although you were probably taught in your undergraduate psychology statistics course to think of the t-test as a stand-alone statistical tool, __the t-test is actually just a special case of the linear model__. Let us explain.

Output from the linear model specified in the upcoming code will include:

1) an estimate of the population mean for the low education group $\mu_1$, 
2) the standard error of the estimate of $\mu_1$, 
3) an estimate of $\mu_2-\mu_1$ (denoted as $\beta_1$), 
4) the standard error of the estimate of $\beta_1$, and 
5) the population standard deviation $\sigma$ (referred to as the residual standard error). 

__The null and alternative hypotheses for this linear model look different from those of the t-test you're familiar with, but you'll soon see that retaining/rejecting the null hypothesis results in the same conclusion.__ The null and alternative hypotheses are:

$H_0: \beta_1=0$ and

$H_1: \beta_1\neq0$,
where $\beta_1$ represents $\mu_2-\mu_1$. 

__If $\beta_1$ is statistically significant (p < .05), we reject the null hypothesis and conclude that $\beta_1$ is significantly different from zero.__ Copy and paste the following code into your R script and run it.
```{r, results = "hide", warning = FALSE, message = FALSE}
mod2 <- lm(MMSE ~ educ, data = simdata) # Fit a linear model 
summary(mod2) # Examine the model output
```

## Interpreting the Model Results
The line of code 
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[1]
``` 
outputs __the sample mean $\bar{x}_1$ for group "0"__ (the low education group). $\bar{x}_1$ is a point estimate of $\mu_1$ (the population mean of $x_1$, where $x_1$ represents the simulated MMSE scores for group "0"). The line of code
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[2]
``` 
outputs __the estimate of $\beta_1$__, the estimated difference between $\mu_1$ and $\mu_2$. The line of code 
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[1] + summary(mod2)$coefficient[2]
```
outputs __the estimate of $\mu_1+\beta_1$__. Since $\beta_1$ is the estimated difference between $\mu_1$ and $\mu_2$, it follows that $\mu_1+\beta_1=\mu_2$. In other words, the above line of code outputs the sample mean $\bar{x}_2$ for group "1" (the high education group), and $\bar{x}_2$ is a point estimate of $\mu_2$ (where $x_2$ represents the simulated MMSE scores for group "1"). The line of code 
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[ , 2]
```
outputs __the standard errors of $\mu_1$ and $\beta_1$__, repsectively. Remember from Module 1, the standard error is a measure of sampling variability, and sampling variability tells us to what degree we should be confident that our sample statistic is an accurate estimate of the population parameter. That is, sampling variability tells us how far the typical sample statistic is from the "true" value of the parameter in the population. If you need a refresher on the concept of sampling variability, return to the demonstration of the sampling distribution in the section titled Interpreting the Model Results from Module 1. 

Finally, the line of code
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$sigma
```
outputs __the sample standard deviation $s$__, a point estimate of $\sigma$ (the population standard deviation). $s$ represents the spread of $x$ about its mean, where $x$ denotes the simulated MMSE scores. You may have noticed that the model output only contains a single estimate of $\sigma$ (as opposed to containing estimates of both $\sigma_1$ and $\sigma_2$). This is because we've assumed the population standard deviation is the same for both groups. In practice, you would test this assumption. (As a note, we didn't test this assumption because we happen to know that the distributions from which the MMSE scores were simulated had the same standard deviation ($\sigma=1.25$). If in practice, you ran a test of homoscedasticity of variance on your sample and found that the assumption was likely violated, you would need to specify a model that estimates separate standard deviations for each group. In your undergraduate psychology statistics course, you may have learned about the Welch's t-test, which is a t-test that addresses violated assumptions of homescedasticity by estimating a separate standard deviation for each group.)

__The main piece of model output that must be evaluated to address our research question is whether or not the estimate of $\beta_1$ (the estimated difference between $\mu_1$ and $\mu_2$) is statistically significant (p < .05)__. If p < .05, we reject the null hypothesis and conclude that $\beta_1$ is significantly different from zero.

## Interpreting the p Value
The "p" we're referring to when we evaluate whether or not "p < .05" is the p value, whose interpretation relies on the concept of long-run frequencies as discussed in the demonstration of the sampling distribution in Module 1. 

To better understand the long-run interpretation of the p value in the context of our current analysis, imagine drawing many samples of size _n_ from a population, conducting a two-tailed, two independent samples t-test on each sample, and saving the test statistic resulting from each t-test conducted. A histogram of these test statistics would represent the sampling distribution of the test statistic.

Now, think about our current analysis. The line of code
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[2, 3]
```
outputs __the test statistic we obtained from our one-tailed, two independent samples t-test__. The line of code
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[2, 4]
```
outputs __the corresponding p value, which is an estimate of the proportion of test statistics in the sampling distribution of the test statistic that are equal to or more extreme than the test statistic we obtained, assuming that the null hypothesis is true.__ In other words, we estimate that
```{r, results = "hide", warning = FALSE, message = FALSE}
summary(mod2)$coefficient[2, 4]*100
```
percent of the test statistics in the sampling distribution of the test statistic would be equal to or more extreme than the test statistic we obtained if the null hypothesis were true. Put simply, __it would be extremely rare to observe the test statistic we obtained if the null hypothesis were true, so we conclude that the null hypothesis is likely false.__

__It is important to note that the p value does not represent the probability of the null hypothesis being true (Gigerenzer, Krauss, & Vitouch, 2004; Kruschke & Liddell, 2018).__ To reiterate, the p value represents the proportion of test statistics in the sampling distribution of the test statistic that are equal to or more extreme than the test statistic we obtained, assuming the null hypothesis is true. While there are statistical tools we can use to obtain the probability of a null hypothesis being true, the p value is not one of them. 

### Evaluating Your Understanding 
Please __return to the Qualtrics survey__ to answer a few questions designed to evaluate your understanding of the material presented in this module.

## References 
Folstein, M. F., Folstein, S. E., & McHugh, P. R. (1975). “Mini-mental state”: a practical method for grading the cognitive state of patients for the clinician. Journal of psychiatric research, 12(3), 189-198.

Gigerenzer, G., Krauss, S., & Vitouch, O. (2004). The null ritual. The Sage handbook of quantitative methodology for the social sciences, 391-408.

Kruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin & Review, 25(1), 178-206.

Le Carret, N., Lafont, S., Letenneur, L., Dartigues, J. F., Mayo, W., & Fabrigoule, C. (2003). The effect of education on cognitive performances and its implication for the constitution of the cognitive reserve. Developmental neuropsychology, 23(3), 317-337.

Letenneur, L., Gilleron, V., Commenges, D., Helmer, C., Orgogozo, J. M., & Dartigues, J. F. (1999). Are sex and educational level independent predictors of dementia and Alzheimer’s disease ? Inci- dence data from the PAQUID project. Journal of Neurology, Neurosurgery & Psychiatry, 66(2), 177–183.

McClave, J. T., and Sincich, T. (2013). Statistics. London, England: Pearson Education. 

Peck, R., & Devore, J. L. (2011). Statistics: The exploration & analysis of data. Cengage Learning.

Siu, A. L. (1991). Screening for dementia and investigating its causes. Annals of Internal Medicine, 115(2), 122-132.

Stern, Y., Gurland, B., Tatemichi, T. K., Tang, M. X., Wilder, D., & Mayeux, R. (1994). Influence of ed-
ucation and occupation on the incidence of Alzheimer’s disease. Journal of the American Medical
Association, 271, 1004–1010.

Witte, R. S., and Witte, J. S. (2016), Statistics. Hoboken, NJ: Wiley.